{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark The Definite Guide - 추천\n",
    "- 사람들의 평점을 통한 명시적 선호 또는 관찰된 행동을 통한 암시적 선호도를 연구함으로써 특정 사용자와 다른 사용자 사이의 유사성이나 사용자가 선호나는 특정 제품과 다른 제품 간의 유사성을 도출하여 사용자가 좋아할 많난 것을 추천 할 수 있음\n",
    "- 이러한 유사성을 기반으로 사용자에게 새로운 추천을 할수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활용 사례\n",
    "- 추천 엔진은 가장 성공적인 빅데이터 활용 사례 중  하나\n",
    "- Spark는 대규모 추천을 위해 오픈소스 도구로 사용되고 있음\n",
    "- ex) \n",
    "    - 영화 추천\n",
    "    - 과목 추천\n",
    "- Spark에서는 추천 위한 알고리즘으로 ALS(Alternating Least Square - 교차최소제곱)을 제공\n",
    "    - Collaborative filtering 기술을 활용하여 사용자가 과거에 상호작용한 아이템들을 기반으로 추천을 함\n",
    "    - 사용자 또는 아이템에 대한 추가적인 특징이 필요하지 않음\n",
    "- ALS 외에 연관 규칙을 찾아내는 빈발 패턴 마이닝도 제공함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS(교차최소제곱) 알고리즘을 사용하여 협업 필터링 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 사용하여 모델을 학습하기\n",
    "ratings = spark.read.text(\"data/sample_movielens_ratings.txt\")\n",
    "\n",
    "ratings = (\n",
    "    ratings.rdd.toDF()\n",
    "    .selectExpr(\"split(value, '::') as col\")\n",
    "    .selectExpr(\n",
    "    \"cast(col[0] as int) as userId\",\n",
    "    \"cast(col[1] as int) as movieId\",\n",
    "    \"cast(col[2] as float) as rating\",\n",
    "    \"cast(col[3] as long) as timestamp\")\n",
    ")\n",
    "\n",
    "training, test = ratings.randomSplit([0.8,0.2])\n",
    "\n",
    "als = (ALS()\n",
    "       .setMaxIter(5)\n",
    "       .setRegParam(0.01)\n",
    "       .setUserCol(\"userId\")\n",
    "       .setItemCol(\"movieId\")\n",
    "       .setRatingCol(\"rating\")\n",
    "      )\n",
    "\n",
    "alsModel = als.fit(training)\n",
    "\n",
    "predictions = alsModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings = sc.textFile(\"data/sample_movielens_ratings.txt\")\n",
    "#ratings = ratings.map((lambda l: l.split(\"::\")))\n",
    "#ratings = spark.createDataFrame(ratings,['userid','movieid','rate','timeStamp'])\n",
    "\n",
    "#ratings = (ratings\n",
    "#           .withColumn(\"userId\",(ratings['userid']).cast(\"integer\"))\n",
    "#           .withColumn(\"movieId\",(ratings['movieid']).cast(\"integer\"))\n",
    "#           .withColumn(\"rating\",(ratings['rate']).cast(\"float\")).drop(\"rate\")\n",
    "#           .withColumn(\"timestamp\",(ratings['timeStamp']).cast(\"long\"))\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|userId|            col|\n",
      "+------+---------------+\n",
      "|    28|[30, 5.4756284]|\n",
      "|    28| [92, 5.052089]|\n",
      "|    28|[12, 4.8499913]|\n",
      "|    28|[81, 4.6342797]|\n",
      "|    28| [49, 4.126742]|\n",
      "|    28| [69, 4.092031]|\n",
      "|    28|[93, 4.0766826]|\n",
      "|    28|[89, 4.0483093]|\n",
      "|    28| [2, 3.9828472]|\n",
      "|    28|[40, 3.6615667]|\n",
      "|    26| [74, 5.641425]|\n",
      "|    26| [30, 5.542386]|\n",
      "|    26|[51, 5.4557705]|\n",
      "|    26|[32, 5.2386336]|\n",
      "|    26|[94, 5.1843386]|\n",
      "|    26| [88, 5.167331]|\n",
      "|    26|  [7, 5.012852]|\n",
      "|    26|[98, 4.9463615]|\n",
      "|    26|[22, 4.8742166]|\n",
      "|    26|[75, 4.4384103]|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 형태의 userId와 배열 형태의 추천 결과 및 각 영화에 대한 평점을 반환\n",
    "alsModel.recommendForAllUsers(10).selectExpr(\"userId\", \"explode(recommendations)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|movieId|            col|\n",
      "+-------+---------------+\n",
      "|     31| [7, 2.9600422]|\n",
      "|     31| [8, 2.8510668]|\n",
      "|     31|[12, 2.7046494]|\n",
      "|     31| [6, 2.3811903]|\n",
      "|     31|[21, 2.3764756]|\n",
      "|     31| [1, 2.1563532]|\n",
      "|     31| [9, 2.0135367]|\n",
      "|     31|[25, 1.8588212]|\n",
      "|     31|[23, 1.7739711]|\n",
      "|     31|[15, 1.7601122]|\n",
      "|     85| [8, 5.0888376]|\n",
      "|     85|[16, 4.6845336]|\n",
      "|     85|  [7, 3.968389]|\n",
      "|     85|[24, 3.7878375]|\n",
      "|     85|[11, 3.7300146]|\n",
      "|     85|[12, 3.4305716]|\n",
      "|     85|[21, 3.1815712]|\n",
      "|     85| [1, 3.1612375]|\n",
      "|     85| [0, 2.9950883]|\n",
      "|     85| [6, 2.8789682]|\n",
      "+-------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# movieId와 영화별 상위 사용자를 DataFrame 형태로 반환\n",
    "alsModel.recommendForAllItems(10).selectExpr(\"movieId\", \"explode(recommendations)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추천을 위한 평가기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 2.232471\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = (\n",
    "    RegressionEvaluator()\n",
    "    .setMetricName(\"rmse\")\n",
    "    .setLabelCol(\"rating\")\n",
    "    .setPredictionCol(\"prediction\")\n",
    ")\n",
    "\n",
    "rsme = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = %f\" % rsme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성과 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 회귀 평가지표\n",
    "- 각 예측값이 해당 사용자 및 아이템의 실제 평가 결과와 얼마나 가까운지 간단히 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.evaluation.RegressionMetrics'>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics\n",
    "\n",
    "regComparison = predictions.select(\"rating\",\"prediction\")\\\n",
    ".rdd.map(lambda x: (x(0),x(1)))\n",
    "\n",
    "metrics = RegressionMetrics(regComparison)\n",
    "print(type(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순위 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RankingMetrics, RegressionMetrics\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "perUserActual = (\n",
    "    predictions\n",
    "    .where(\"rating > 2.5\")\n",
    "    .groupBy(\"userId\")\n",
    "    .agg(expr(\"collect_set(movieId) as movies\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|userId|             movies|\n",
      "+------+-------------------+\n",
      "|    28|               [19]|\n",
      "|    26|[81, 68, 24, 4, 23]|\n",
      "|    27|           [66, 19]|\n",
      "|    12|           [31, 91]|\n",
      "|    22|   [70, 32, 68, 80]|\n",
      "|     1|               [77]|\n",
      "|    13|           [53, 72]|\n",
      "|    16|           [51, 96]|\n",
      "|     6|           [61, 25]|\n",
      "|     3|            [18, 8]|\n",
      "|    20|               [90]|\n",
      "|     5|   [20, 56, 36, 55]|\n",
      "|    15|                [1]|\n",
      "|    17|   [46, 22, 94, 55]|\n",
      "|     9|        [2, 32, 14]|\n",
      "|     4|           [87, 41]|\n",
      "|     8|       [96, 72, 29]|\n",
      "|    23|   [48, 50, 87, 55]|\n",
      "|     7|               [25]|\n",
      "|    10|    [2, 89, 42, 25]|\n",
      "+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perUserActual.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "perUserPredictions = (\n",
    "    predictions\n",
    "    .orderBy(col(\"userId\"), expr(\"prediction DESC\"))\n",
    "    .groupBy(\"userId\")\n",
    "    .agg(expr(\"collect_list(movieId) as movies\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|              movies|\n",
      "+------+--------------------+\n",
      "|    28|[85, 59, 63, 52, ...|\n",
      "|    26|[81, 97, 16, 48, ...|\n",
      "|    27|[43, 28, 31, 42, ...|\n",
      "|    12|[74, 8, 84, 78, 1...|\n",
      "|    22|[16, 70, 68, 26, ...|\n",
      "|     1|[74, 43, 12, 13, ...|\n",
      "|    13|[72, 53, 22, 98, ...|\n",
      "|     6|[96, 39, 68, 22, ...|\n",
      "|    16|[34, 99, 36, 96, ...|\n",
      "|     3|[0, 2, 8, 15, 70,...|\n",
      "|    20|[93, 39, 90, 78, ...|\n",
      "|     5|[84, 15, 55, 99, ...|\n",
      "|    19|[84, 58, 37, 61, ...|\n",
      "|    15|[1, 97, 82, 32, 7...|\n",
      "|     9|[54, 59, 22, 73, ...|\n",
      "|    17|[46, 94, 22, 57, ...|\n",
      "|     4|[89, 41, 15, 87, ...|\n",
      "|     8|[29, 11, 18, 7, 2...|\n",
      "|    23|[43, 29, 55, 77, ...|\n",
      "|     7|[63, 11, 32, 55, ...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perUserPredictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "perUserActualPred = (perUserActual\n",
    "                     .join(perUserPredictions, [\"userId\"]).rdd\n",
    "                     .map(lambda row:(row[1], row[2][:15]))\n",
    "                    )\n",
    "ranks = RankingMetrics(perUserActualPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.503448275862069"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평균정밀도의 평균으로 알고리즘 얼마나 정확한지 확인\n",
    "# 특정 순위 구간의 정확도를 도출하여 주로 어느 구간에서 추천이 실패하는지 파악 가능\n",
    "ranks.meanAveragePrecision\n",
    "ranks.precisionAt(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "# EXAMPLE\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2RDD(path):\n",
    "    rdd = spark.sparkContext.textFile(path)\n",
    "    rdd_header = rdd.take(1)[0]\n",
    "    rdd = rdd\\\n",
    "        .filter(lambda line: line!=rdd_header) \\\n",
    "        .map(lambda line: line.split(\",\")) \\\n",
    "        .map(lambda tokens: (tokens[0],tokens[1],tokens[2])) \\\n",
    "        .cache()\n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "small_ratings = os.path.join('../data/ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_rdd = spark.sparkContext.textFile(small_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ratings_rdd_header = small_ratings_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId,movieId,rating,timestamp']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_ratings_rdd_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = (small_ratings_rdd\n",
    "           .filter(lambda line: line!=small_ratings_rdd_header[0])\n",
    "           .map(lambda line: line.split(\",\"))\n",
    "           .map(lambda tokens: (tokens[0],tokens[1],tokens[2]))\n",
    "           .cache()\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingspath = os.path.join('../data/ml-latest-small/ratings.csv')\n",
    "ratings = csv2RDD(small_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviespath = os.path.join('../data/ml-latest-small/movies.csv')\n",
    "movies = csv2RDD(moviespath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'Toy Story (1995)', 'Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " ('2', 'Jumanji (1995)', 'Adventure|Children|Fantasy'),\n",
       " ('3', 'Grumpier Old Men (1995)', 'Comedy|Romance')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train, test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "train, org_validation, org_test = ratings.randomSplit([6,2,2], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', '6', '4.0'), ('1', '47', '5.0'), ('1', '163', '5.0')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org_validation.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = org_validation.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = org_test.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS 모델링\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "#----------------ml package(DataFrame)------------------\n",
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(rank=10, maxIter=20, userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\")\n",
    "model = als.fit(trainDf)\n",
    "predictions = model.transform(testDf)\n",
    "\n",
    "#----------------mllib package(RDD)----------------\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "model = ALS.train(trainRdd, 10, seed=3, iterations=20)\n",
    "predictions = model.predictAll(testRdd).map(lambda r: (r.user, r.product, r.rating))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS 모델에 필요한 설정이 있다.\n",
    "* rank는 숨겨진 요인 latent factors의 수\n",
    "* iterations 반복회수\n",
    "* lambda는 regularization 계수 (높으면 regularizaton 높음..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 5\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "rank=4\n",
    "# start for\n",
    "# ranks = [4, 8, 12]\n",
    "# for rank in ranks:\n",
    "model = ALS.train(train,rank,seed=seed,iterations=iterations,lambda_=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측\n",
    "\n",
    "#### 전체\n",
    "\n",
    "```predictAll()``` 함수는 ```ratings``` 평가점수를 예측한다. 즉 사용자의 영화에 대한 평가점수가 없는 경우, 몇 점인지 예측하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predictAll(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=610, product=81132, rating=3.1807547132989855),\n",
       " Rating(user=480, product=6156, rating=3.462198788774775)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predictions.map(lambda r: ((r[0], r[1]), r[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_and_preds = org_validation\\\n",
    "    .map(lambda r: ((int(r[0]), int(r[1])), float(r[2])))\\\n",
    "    .join(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 2193), (4.0, 4.214270983630589)),\n",
       " ((3, 26409), (4.5, 0.2902626066967151)),\n",
       " ((4, 914), (5.0, 4.125248624296204))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자별 예측\n",
    "- userId, movieId를 넣으면 평가점수 예측 할수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.790980724422168"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1번 사용자가 1번 영화에 대한 예측 rating은 대략 4.79\n",
    "model.predict(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번 사용자의 상위 10개 추천\n",
    "user1Top10 = model.recommendProducts(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=1, product=3379, rating=6.4158343229672745),\n",
       " Rating(user=1, product=6818, rating=6.253854681185788),\n",
       " Rating(user=1, product=7748, rating=6.180248513720873),\n",
       " Rating(user=1, product=33649, rating=6.1540872085397025),\n",
       " Rating(user=1, product=59018, rating=6.063044888164292),\n",
       " Rating(user=1, product=3200, rating=6.004648389795263),\n",
       " Rating(user=1, product=58301, rating=6.003154000537293),\n",
       " Rating(user=1, product=2239, rating=5.807160201242671),\n",
       " Rating(user=1, product=5485, rating=5.806598376177139),\n",
       " Rating(user=1, product=93988, rating=5.795515866260636)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user1Top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['On the Beach (1959)']\n",
      "['Come and See (Idi i smotri) (1985)']\n",
      "['Pierrot le fou (1965)']\n",
      "['Saving Face (2004)']\n",
      "['\"Visitor']\n",
      "['\"Last Detail']\n",
      "['Funny Games U.S. (2007)']\n",
      "[\"Swept Away (Travolti da un insolito destino nell'azzurro mare d'Agosto) (1975)\"]\n",
      "['Tadpole (2002)']\n",
      "['North & South (2004)']\n"
     ]
    }
   ],
   "source": [
    "top10movies = user1Top10[1][1]\n",
    "for i in range(0,10):\n",
    "    print(movies.lookup(str(user1Top10[i][1])))\n",
    "    #print(user1Top10[i][1])\n",
    "#movies.lookup('93988')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['North & South (2004)']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.lookup('93988')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true', inferschema='true').load('../data/ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.drop('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      1|   4.0|\n",
      "|     1|      3|   4.0|\n",
      "|     1|      6|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read.format('com.databricks.spark.csv')\\\n",
    ".options(header='true', inferschema='true').load('../data/ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, org_validation_df, org_test_df = ratings_df.randomSplit([0.6,0.2,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = org_validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = org_test_df.drop('rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = (ALS()\n",
    "       .setMaxIter(10)\n",
    "       .setRegParam(0.1)\n",
    "       .setUserCol(\"userId\")\n",
    "       .setItemCol(\"movieId\")\n",
    "       .setRatingCol(\"rating\")\n",
    "      )\n",
    "\n",
    "\n",
    "alsModel = als.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_predictions = alsModel.transform(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|   385|    471|   4.0| 2.4761214|\n",
      "|   500|    471|   1.0| 2.2541206|\n",
      "|   176|    471|   5.0| 4.1756897|\n",
      "|   216|    471|   3.0| 3.2429502|\n",
      "|   411|    471|   4.0| 3.6109314|\n",
      "|   260|    471|   4.5|  3.319919|\n",
      "|   357|    471|   3.5| 3.8527763|\n",
      "|   307|    833|   1.0| 1.8112105|\n",
      "|   608|    833|   0.5| 2.5559247|\n",
      "|   177|   1088|   3.5|  3.600533|\n",
      "|   132|   1088|   4.0|   2.95846|\n",
      "|    64|   1088|   4.0|  3.581046|\n",
      "|   286|   1088|   3.5| 3.0356274|\n",
      "|   387|   1088|   1.5| 2.5480225|\n",
      "|   226|   1088|   1.0| 3.2058072|\n",
      "|   188|   1088|   4.0|  4.021937|\n",
      "|    68|   1088|   3.5| 3.1473124|\n",
      "|   600|   1088|   3.5| 2.9869893|\n",
      "|   517|   1088|   1.0| 3.1542857|\n",
      "|   385|   1238|   3.0| 2.8106213|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|userId|                col|\n",
      "+------+-------------------+\n",
      "|     1| [33649, 5.7864656]|\n",
      "|     1|    [3022, 5.81411]|\n",
      "|     1|   [3379, 5.595037]|\n",
      "|     1|[177593, 5.6490088]|\n",
      "|     1|  [26258, 5.941104]|\n",
      "|     2| [32892, 4.7452865]|\n",
      "|     2|    [213, 4.748828]|\n",
      "|     2|   [7121, 4.694185]|\n",
      "|     2|[131724, 4.9052835]|\n",
      "|     2|[177593, 5.1851015]|\n",
      "|     3| [70946, 4.9118304]|\n",
      "|     3|  [6835, 4.9118304]|\n",
      "|     3|   [5181, 4.871731]|\n",
      "|     3|  [5746, 4.9118304]|\n",
      "|     3|  [5919, 4.9118304]|\n",
      "|     4|   [456, 5.5200477]|\n",
      "|     4|   [3030, 5.598499]|\n",
      "|     4|[132333, 5.2960567]|\n",
      "|     4|  [25850, 5.366564]|\n",
      "|     4|   [1147, 5.617336]|\n",
      "+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 형태의 userId와 배열 형태의 추천 결과 및 각 영화에 대한 평점을 반환\n",
    "alsModel.recommendForAllUsers(5).selectExpr(\"userId\", \"explode(recommendations)\").orderBy(\"userId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|movieId|             col|\n",
      "+-------+----------------+\n",
      "|      1| [43, 4.9595304]|\n",
      "|      1|  [77, 4.920113]|\n",
      "|      1|[452, 4.8996873]|\n",
      "|      1|  [171, 4.96419]|\n",
      "|      1|[429, 4.9567018]|\n",
      "|      2|[337, 4.3921747]|\n",
      "|      2| [267, 4.413191]|\n",
      "|      2|[594, 4.4981236]|\n",
      "|      2| [498, 4.444351]|\n",
      "|      2|[475, 4.3758307]|\n",
      "|      3|  [43, 4.627588]|\n",
      "|      3| [543, 4.320625]|\n",
      "|      3| [77, 4.2711987]|\n",
      "|      3| [523, 4.156305]|\n",
      "|      3|[267, 4.1473327]|\n",
      "|      4|[243, 3.4013493]|\n",
      "|      4| [43, 3.5434914]|\n",
      "|      4|[337, 3.4515815]|\n",
      "|      4|[557, 3.4062204]|\n",
      "|      4| [594, 3.582818]|\n",
      "+-------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# movieId와 영화별 상위 사용자를 DataFrame 형태로 반환\n",
    "alsModel.recommendForAllItems(5).selectExpr(\"movieId\", \"explode(recommendations)\").orderBy(\"movieId\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순위 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RankingMetrics, RegressionMetrics\n",
    "from pyspark.sql.functions import col, expr\n",
    "# 평점  4 이상\n",
    "perUserActual = (\n",
    "    validate_predictions\n",
    "    .where(\"prediction > 4\")\n",
    "    .groupBy(\"userId\")\n",
    "    .agg(expr(\"collect_set(movieId) as movies\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|userId|              movies|\n",
      "+------+--------------------+\n",
      "|     1|[2542, 1206, 590,...|\n",
      "|     3|       [7899, 26409]|\n",
      "|     4|               [215]|\n",
      "|     5|               [608]|\n",
      "|     6|[981, 27, 318, 37...|\n",
      "|     7|       [4306, 31878]|\n",
      "|     8|               [457]|\n",
      "|     9|  [1987, 3328, 2300]|\n",
      "|    10|    [137595, 112006]|\n",
      "|    11|[150, 529, 2028, ...|\n",
      "|    12|[6942, 920, 40629...|\n",
      "|    15|              [1196]|\n",
      "|    16|              [3741]|\n",
      "|    17|[750, 1259, 81932...|\n",
      "|    18|[4973, 114066, 18...|\n",
      "|    19|[1355, 2227, 2263...|\n",
      "|    20|[661, 3536, 2687,...|\n",
      "|    21|[86068, 122886, 1...|\n",
      "|    23|               [912]|\n",
      "|    24|  [27773, 1197, 457]|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perUserActual.orderBy(\"userId\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|     1|   35|\n",
      "|     2|    3|\n",
      "|     3|    6|\n",
      "|     4|   44|\n",
      "|     5|    9|\n",
      "|     6|   53|\n",
      "|     7|   36|\n",
      "|     8|   11|\n",
      "|     9|    6|\n",
      "|    10|   21|\n",
      "|    11|   17|\n",
      "|    12|   12|\n",
      "|    13|    3|\n",
      "|    14|   12|\n",
      "|    15|   30|\n",
      "|    16|   27|\n",
      "|    17|   23|\n",
      "|    18|  101|\n",
      "|    19|  125|\n",
      "|    20|   45|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "org_validation_df.groupBy('userId').count().orderBy('userId').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+---+---+---+---+---+---+---+---+\n",
      "|userId|0.5|1.0|1.5|2.0|2.5|3.0|3.5|4.0|4.5|5.0|\n",
      "+------+---+---+---+---+---+---+---+---+---+---+\n",
      "|     1|  0|  0|  0|  0|  0|  3|  0|  7|  0| 25|\n",
      "|     2|  0|  0|  0|  1|  0|  0|  1|  1|  0|  0|\n",
      "|     3|  3|  0|  0|  1|  0|  0|  0|  0|  2|  0|\n",
      "|     4|  0|  4|  0|  7|  0| 12|  0| 13|  0|  8|\n",
      "|     5|  0|  0|  0|  1|  0|  2|  0|  3|  0|  3|\n",
      "|     6|  0|  1|  0|  1|  0| 27|  0| 18|  0|  6|\n",
      "|     7|  2|  4|  4|  0|  1|  4|  4|  6|  7|  4|\n",
      "|     8|  0|  0|  0|  0|  0|  6|  0|  2|  0|  3|\n",
      "|     9|  0|  0|  0|  1|  0|  2|  0|  1|  0|  2|\n",
      "|    10|  3|  2|  0|  0|  2|  2|  5|  4|  1|  2|\n",
      "|    11|  0|  0|  0|  1|  0|  5|  0|  4|  0|  7|\n",
      "|    12|  0|  0|  0|  0|  0|  0|  1|  0|  1| 10|\n",
      "|    13|  0|  0|  0|  0|  0|  2|  0|  1|  0|  0|\n",
      "|    14|  0|  1|  0|  2|  0|  3|  0|  3|  0|  3|\n",
      "|    15|  0|  1|  0|  1|  2|  6|  5|  8|  3|  4|\n",
      "|    16|  0|  0|  0|  0|  1|  3|  9| 12|  1|  1|\n",
      "|    17|  0|  0|  0|  0|  0|  0|  3|  8| 10|  2|\n",
      "|    18|  1|  1|  1|  0|  3| 13| 32| 29| 20|  1|\n",
      "|    19|  0| 12|  0| 52|  0| 49|  0|  7|  0|  5|\n",
      "|    20|  2|  2|  1|  3|  2|  4|  6| 11|  8|  6|\n",
      "+------+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "org_validation_df.groupBy('userId').pivot('rating').agg({\"rating\":\"count\"}).fillna(0).orderBy(\"userId\").show()\n",
    "#bicycle.groupBy('year').pivot('month').agg({\"count\":\"sum\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
